Using cpu device
Wrapping the env in a VecTransposeImage.
Logging to runs/ppo_breakout/PPO_4
/opt/anaconda3/lib/python3.12/site-packages/stable_baselines3/common/callbacks.py:418: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x134d0f9e0> != <stable_baselines3.common.vec_env.vec_video_recorder.VecVideoRecorder object at 0x13482da60>
  warnings.warn("Training and eval env are not of the same type" f"{self.training_env} != {self.eval_env}")
Saving video to /Users/ruchi/dev/AP_Research_Atari/videos/nhbpr250/rl-video-step-0-to-step-200.mp4
Moviepy - Building video /Users/ruchi/dev/AP_Research_Atari/videos/nhbpr250/rl-video-step-0-to-step-200.mp4.
Moviepy - Writing video /Users/ruchi/dev/AP_Research_Atari/videos/nhbpr250/rl-video-step-0-to-step-200.mp4
/opt/anaconda3/lib/python3.12/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.

Moviepy - Done !
Moviepy - video ready /Users/ruchi/dev/AP_Research_Atari/videos/nhbpr250/rl-video-step-0-to-step-200.mp4
  warnings.warn(
Saving video to /Users/ruchi/dev/AP_Research_Atari/videos/nhbpr250/rl-video-step-2000-to-step-2200.mp4
Moviepy - Building video /Users/ruchi/dev/AP_Research_Atari/videos/nhbpr250/rl-video-step-2000-to-step-2200.mp4.
Moviepy - Writing video /Users/ruchi/dev/AP_Research_Atari/videos/nhbpr250/rl-video-step-2000-to-step-2200.mp4
                                                                                                                                                         

Moviepy - Done !
Moviepy - video ready /Users/ruchi/dev/AP_Research_Atari/videos/nhbpr250/rl-video-step-2000-to-step-2200.mp4
Saving video to /Users/ruchi/dev/AP_Research_Atari/videos/nhbpr250/rl-video-step-4000-to-step-4200.mp4
Moviepy - Building video /Users/ruchi/dev/AP_Research_Atari/videos/nhbpr250/rl-video-step-4000-to-step-4200.mp4.
Moviepy - Writing video /Users/ruchi/dev/AP_Research_Atari/videos/nhbpr250/rl-video-step-4000-to-step-4200.mp4

Moviepy - Done !
Moviepy - video ready /Users/ruchi/dev/AP_Research_Atari/videos/nhbpr250/rl-video-step-4000-to-step-4200.mp4
Saving video to /Users/ruchi/dev/AP_Research_Atari/videos/nhbpr250/rl-video-step-6000-to-step-6200.mp4
Moviepy - Building video /Users/ruchi/dev/AP_Research_Atari/videos/nhbpr250/rl-video-step-6000-to-step-6200.mp4.
Moviepy - Writing video /Users/ruchi/dev/AP_Research_Atari/videos/nhbpr250/rl-video-step-6000-to-step-6200.mp4

Moviepy - Done !
Moviepy - video ready /Users/ruchi/dev/AP_Research_Atari/videos/nhbpr250/rl-video-step-6000-to-step-6200.mp4
Saving video to /Users/ruchi/dev/AP_Research_Atari/videos/nhbpr250/rl-video-step-8000-to-step-8200.mp4
Moviepy - Building video /Users/ruchi/dev/AP_Research_Atari/videos/nhbpr250/rl-video-step-8000-to-step-8200.mp4.
Moviepy - Writing video /Users/ruchi/dev/AP_Research_Atari/videos/nhbpr250/rl-video-step-8000-to-step-8200.mp4

Moviepy - Done !
Moviepy - video ready /Users/ruchi/dev/AP_Research_Atari/videos/nhbpr250/rl-video-step-8000-to-step-8200.mp4
Saving video to /Users/ruchi/dev/AP_Research_Atari/videos/nhbpr250/rl-video-step-10000-to-step-10200.mp4
Moviepy - Building video /Users/ruchi/dev/AP_Research_Atari/videos/nhbpr250/rl-video-step-10000-to-step-10200.mp4.
Moviepy - Writing video /Users/ruchi/dev/AP_Research_Atari/videos/nhbpr250/rl-video-step-10000-to-step-10200.mp4

Moviepy - Done !
Moviepy - video ready /Users/ruchi/dev/AP_Research_Atari/videos/nhbpr250/rl-video-step-10000-to-step-10200.mp4
Saving video to /Users/ruchi/dev/AP_Research_Atari/videos/nhbpr250/rl-video-step-12000-to-step-12200.mp4
Moviepy - Building video /Users/ruchi/dev/AP_Research_Atari/videos/nhbpr250/rl-video-step-12000-to-step-12200.mp4.
Moviepy - Writing video /Users/ruchi/dev/AP_Research_Atari/videos/nhbpr250/rl-video-step-12000-to-step-12200.mp4

Moviepy - Done !
Moviepy - video ready /Users/ruchi/dev/AP_Research_Atari/videos/nhbpr250/rl-video-step-12000-to-step-12200.mp4
Saving video to /Users/ruchi/dev/AP_Research_Atari/videos/nhbpr250/rl-video-step-14000-to-step-14200.mp4
Moviepy - Building video /Users/ruchi/dev/AP_Research_Atari/videos/nhbpr250/rl-video-step-14000-to-step-14200.mp4.
Moviepy - Writing video /Users/ruchi/dev/AP_Research_Atari/videos/nhbpr250/rl-video-step-14000-to-step-14200.mp4

Moviepy - Done !
Moviepy - video ready /Users/ruchi/dev/AP_Research_Atari/videos/nhbpr250/rl-video-step-14000-to-step-14200.mp4
Saving video to /Users/ruchi/dev/AP_Research_Atari/videos/nhbpr250/rl-video-step-16000-to-step-16200.mp4
Moviepy - Building video /Users/ruchi/dev/AP_Research_Atari/videos/nhbpr250/rl-video-step-16000-to-step-16200.mp4.
Moviepy - Writing video /Users/ruchi/dev/AP_Research_Atari/videos/nhbpr250/rl-video-step-16000-to-step-16200.mp4

Moviepy - Done !
Moviepy - video ready /Users/ruchi/dev/AP_Research_Atari/videos/nhbpr250/rl-video-step-16000-to-step-16200.mp4
  File "/Users/ruchi/dev/AP_Research_Atari/ppo.py", line 69, in <module>
    model.learn(total_timesteps= 300000,
  File "/opt/anaconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py", line 311, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 323, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 224, in collect_rollouts
    if not callback.on_step():
           ^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/stable_baselines3/common/callbacks.py", line 114, in on_step
    return self._on_step()
           ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/stable_baselines3/common/callbacks.py", line 464, in _on_step
    episode_rewards, episode_lengths = evaluate_policy(
                                       ^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/stable_baselines3/common/evaluation.py", line 94, in evaluate_policy
    new_observations, rewards, dones, infos = env.step(actions)
                                              ^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/stable_baselines3/common/vec_env/base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/stable_baselines3/common/vec_env/vec_video_recorder.py", line 98, in step_wait
    obs, rewards, dones, infos = self.venv.step_wait()
                                 ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/gymnasium/wrappers/common.py", line 513, in step
    obs, reward, terminated, truncated, info = super().step(action)
                                               ^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/gymnasium/core.py", line 322, in step
    return self.env.step(action)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/gymnasium/wrappers/common.py", line 393, in step
    return super().step(action)
           ^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/gymnasium/core.py", line 322, in step
    return self.env.step(action)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/gymnasium/wrappers/common.py", line 285, in step
    return self.env.step(action)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/ale_py/env.py", line 299, in step
    reward += self.ale.act(action_idx, strength)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
